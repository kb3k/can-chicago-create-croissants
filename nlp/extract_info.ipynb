{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import spacy # texthero, spacy, and nltk do not seem to align; pick 1-2\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_str1 = '<span class=\"css-1egxyvc\" data-font-weight=\"bold\">croissant</span>'\n",
    "replace_str2 = '<span class=\"css-1egxyvc\" data-font-weight=\"bold\">croissants</span>'\n",
    "replace_str3 = '<span class=\"css-1egxyvc\" data-font-weight=\"bold\">Croissant</span>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "\n",
    "with open(\"../archive/reviews.txt\", \"r\") as the_file:\n",
    "    while True:\n",
    "        line = the_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        elif len(line) > 3: # \\n\n",
    "            line = line.replace(replace_str1, \"croissant\")\n",
    "            line = line.replace(replace_str2, \"croissant\")\n",
    "            line = line.replace(replace_str3, \"croissant\")\n",
    "            reviews.append(line)\n",
    "\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lost larson bakery : These are the best cinnamon rolls ever. The croissant are also delicious and the service is very efficient”\\n', 'bang bang pie and biscuits : reminded me of a croissant) and light. The actual filling was very good and you can clearly taste”\\n', 'good ambler : minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n']\n"
     ]
    }
   ],
   "source": [
    "print(reviews[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idx0</th>\n",
       "      <td>hendrickx belgian bread crafter</td>\n",
       "      <td>The almond chocolate croissant and french coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx1</th>\n",
       "      <td>lost larson bakery</td>\n",
       "      <td>These are the best cinnamon rolls ever. The cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx2</th>\n",
       "      <td>bang bang pie and biscuits</td>\n",
       "      <td>reminded me of a croissant) and light. The act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx3</th>\n",
       "      <td>good ambler</td>\n",
       "      <td>minutes. - Ham and cheese croissant: croissant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx4</th>\n",
       "      <td>p%C3%A2tisserie coralie</td>\n",
       "      <td>is a croissant desert. Search no more. Very fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           BakeryName  \\\n",
       "idx                                     \n",
       "idx0  hendrickx belgian bread crafter   \n",
       "idx1               lost larson bakery   \n",
       "idx2       bang bang pie and biscuits   \n",
       "idx3                      good ambler   \n",
       "idx4          p%C3%A2tisserie coralie   \n",
       "\n",
       "                                                 Review  \n",
       "idx                                                      \n",
       "idx0  The almond chocolate croissant and french coun...  \n",
       "idx1  These are the best cinnamon rolls ever. The cr...  \n",
       "idx2  reminded me of a croissant) and light. The act...  \n",
       "idx3  minutes. - Ham and cheese croissant: croissant...  \n",
       "idx4  is a croissant desert. Search no more. Very fr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I like this version better but pandas words differently, so later we conform\n",
    "dict_reviews = {review.split(' : ')[0]: review.split(' : ')[1] for review in reviews}\n",
    "\n",
    "names = list(dict_reviews.keys())\n",
    "words = list(dict_reviews.values())\n",
    "index = ['idx'+str(idx) for idx in range(0, len(names))]\n",
    "dict_for_pd = {'idx': index, 'BakeryName': names, 'Review': words}\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_for_pd)\n",
    "df.set_index(\"idx\", inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idx3</th>\n",
       "      <td>good ambler</td>\n",
       "      <td>minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx16</th>\n",
       "      <td>hoosier mama pie company</td>\n",
       "      <td>and cream admixture and a flaky buttery crust almost like that of a croissant. Indecisive and gluttonous as”\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx33</th>\n",
       "      <td>caffe umbria</td>\n",
       "      <td>are the highlight of the show, you absolutely have to get a croissant - it was so flaky and buttery and the muffin was also moist and had a hint of cinnamon!!!”\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx39</th>\n",
       "      <td>abc bakery and deli norridge?hrid=SDxAypM6HgjzV47KHlp0TQ&amp;amp;osq=croissant\"&gt;more&lt;/a&gt;&lt;/span&gt;&lt;/p</td>\n",
       "      <td>of the seductive sweets. I chose a nutella croissant! Fluffy, flaky, sticky hazelnut spread glory. Yes”\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           BakeryName  \\\n",
       "idx                                                                                                     \n",
       "idx3                                                                                      good ambler   \n",
       "idx16                                                                        hoosier mama pie company   \n",
       "idx33                                                                                    caffe umbria   \n",
       "idx39  abc bakery and deli norridge?hrid=SDxAypM6HgjzV47KHlp0TQ&amp;osq=croissant\">more</a></span></p   \n",
       "\n",
       "                                                                                                                                                                   Review  \n",
       "idx                                                                                                                                                                        \n",
       "idx3                                                             minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n  \n",
       "idx16                                                      and cream admixture and a flaky buttery crust almost like that of a croissant. Indecisive and gluttonous as”\\n  \n",
       "idx33  are the highlight of the show, you absolutely have to get a croissant - it was so flaky and buttery and the muffin was also moist and had a hint of cinnamon!!!”\\n  \n",
       "idx39                                                           of the seductive sweets. I chose a nutella croissant! Fluffy, flaky, sticky hazelnut spread glory. Yes”\\n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some peering\n",
    "pd.options.display.max_colwidth = None\n",
    "df[df['Review'].str.contains(\"flak\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoosier mama is not a review on a croissant\n",
    "# not a huge nutella fan, it's just sugar. too easy\n",
    "# caffe umbria and good ambler are the winners based on this.\n",
    "# but let's do more with these reviews\n",
    "# while we r here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BakeryName, Review]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Review'].str.contains(\"artisan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing, filtering stop words, stemming, and lower casing\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words.union({'!', '!!!', '!!!”', '!)', '!),', '!?', '!”', '\"', '\">', '.', \"'\", '\\n'\\\n",
    "                               '&', '(', ')', '),', ').', '+', ',', '-', '--', '&', '...', '.”', '/',\n",
    "                               '”', '…', '=', '/', '<'})\n",
    "\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Prepped'] = df.Review.apply(lambda xyz: \n",
    "                                       [stemmer.stem(word.lower()) \n",
    "                                        for word in wordpunct_tokenize(xyz) \n",
    "                                        if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Prepped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idx0</th>\n",
       "      <td>hendrickx belgian bread crafter</td>\n",
       "      <td>The almond chocolate croissant and french country bread were quite authentic and wonderfully rustic.”\\n</td>\n",
       "      <td>[almond, chocol, croissant, french, countri, bread, quit, authent, wonder, rustic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx1</th>\n",
       "      <td>lost larson bakery</td>\n",
       "      <td>These are the best cinnamon rolls ever. The croissant are also delicious and the service is very efficient”\\n</td>\n",
       "      <td>[best, cinnamon, roll, ever, croissant, also, delici, servic, effici]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx2</th>\n",
       "      <td>bang bang pie and biscuits</td>\n",
       "      <td>reminded me of a croissant) and light. The actual filling was very good and you can clearly taste”\\n</td>\n",
       "      <td>[remind, croissant, light, actual, fill, good, clear, tast]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx3</th>\n",
       "      <td>good ambler</td>\n",
       "      <td>minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n</td>\n",
       "      <td>[minut, ham, chees, croissant, :, croissant, super, flaki, sesam, seed, nice, touch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx4</th>\n",
       "      <td>p%C3%A2tisserie coralie</td>\n",
       "      <td>is a croissant desert. Search no more. Very friendly staff, great tea and coffee. A truly welcome addition to the neighborhood. Best of luck.”\\n</td>\n",
       "      <td>[croissant, desert, search, friend, staff, great, tea, coffe, truli, welcom, addit, neighborhood, best, luck]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           BakeryName  \\\n",
       "idx                                     \n",
       "idx0  hendrickx belgian bread crafter   \n",
       "idx1               lost larson bakery   \n",
       "idx2       bang bang pie and biscuits   \n",
       "idx3                      good ambler   \n",
       "idx4          p%C3%A2tisserie coralie   \n",
       "\n",
       "                                                                                                                                                Review  \\\n",
       "idx                                                                                                                                                      \n",
       "idx0                                           The almond chocolate croissant and french country bread were quite authentic and wonderfully rustic.”\\n   \n",
       "idx1                                     These are the best cinnamon rolls ever. The croissant are also delicious and the service is very efficient”\\n   \n",
       "idx2                                              reminded me of a croissant) and light. The actual filling was very good and you can clearly taste”\\n   \n",
       "idx3                                          minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n   \n",
       "idx4  is a croissant desert. Search no more. Very friendly staff, great tea and coffee. A truly welcome addition to the neighborhood. Best of luck.”\\n   \n",
       "\n",
       "                                                                                                     Review_Prepped  \n",
       "idx                                                                                                                  \n",
       "idx0                             [almond, chocol, croissant, french, countri, bread, quit, authent, wonder, rustic]  \n",
       "idx1                                          [best, cinnamon, roll, ever, croissant, also, delici, servic, effici]  \n",
       "idx2                                                    [remind, croissant, light, actual, fill, good, clear, tast]  \n",
       "idx3                           [minut, ham, chees, croissant, :, croissant, super, flaki, sesam, seed, nice, touch]  \n",
       "idx4  [croissant, desert, search, friend, staff, great, tea, coffe, truli, welcom, addit, neighborhood, best, luck]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semantic analysis ?\n",
    "\n",
    "if someone writes a review on a croissant in chicago, \n",
    "what are they likely to say about it. .. https://www.nltk.org/howto/classify.html\n",
    "or https://www.nltk.org/howto/probability.html\n",
    "\n",
    ">>> from nltk.classify import SklearnClassifier\n",
    ">>> from sklearn.naive_bayes import BernoulliNB\n",
    ">>> from sklearn.svm import SVC\n",
    ">>> train_data = [({\"a\": 4, \"b\": 1, \"c\": 0}, \"ham\"),\n",
    "...               ({\"a\": 5, \"b\": 2, \"c\": 1}, \"ham\"),\n",
    "...               ({\"a\": 0, \"b\": 3, \"c\": 4}, \"spam\"),\n",
    "...               ({\"a\": 5, \"b\": 1, \"c\": 1}, \"ham\"),\n",
    "...               ({\"a\": 1, \"b\": 4, \"c\": 3}, \"spam\")]\n",
    ">>> classif = SklearnClassifier(BernoulliNB()).train(train_data)\n",
    ">>> test_data = [{\"a\": 3, \"b\": 2, \"c\": 1},\n",
    "...              {\"a\": 0, \"b\": 3, \"c\": 7}]\n",
    ">>> classif.classify_many(test_data)\n",
    "['ham', 'spam']\n",
    ">>> classif = SklearnClassifier(SVC(), sparse=False).train(train_data)\n",
    ">>> classif.classify_many(test_data)\n",
    "['ham', 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "items_to_return = []\n",
    "\n",
    "def many_things(string_of_text):\n",
    "    \"\"\"\n",
    "    uses the spacy package to \n",
    "    label words in case its important\n",
    "    to differentiate can and can in the following\n",
    "    sent. as ex. . .\n",
    "    \n",
    "    i can kick the can down the road\n",
    "    \n",
    "    this actually does not work lol\n",
    "    \"\"\"\n",
    "    nlp_mjx = nlp(string_of_text)\n",
    "    for ent in nlp_mjx.ents:\n",
    "        info = str(ent.text) + \"|\" + str(ent.label_)\n",
    "        items_to_return.append(info)\n",
    "    return items_to_return\n",
    "\n",
    "#df['spacy_NLP_ids'] = df['Review'].apply(lambda mjx: many_things(mjx))\n",
    "#df['spacy_NLP_ids_str'] = df['spacy_NLP_ids'].apply(lambda bbg: \" \".join(bbg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Prepped_str'] = df['Review_Prepped'].apply(lambda bbg: \" \".join(bbg))\n",
    "df['word_count'] = df['Review_Prepped_str'].apply(lambda x : nltk.FreqDist(nltk.word_tokenize(x))) #previously Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'croissant': 85,\n",
       " 'chocol': 14,\n",
       " 'coffe': 14,\n",
       " 'good': 12,\n",
       " 'latt': 12,\n",
       " 'chees': 12,\n",
       " 'almond': 11,\n",
       " 'delici': 11,\n",
       " 'also': 10,\n",
       " 'ham': 8,\n",
       " 'best': 8,\n",
       " 'like': 8,\n",
       " 'great': 7,\n",
       " 'sandwich': 7,\n",
       " 'made': 7,\n",
       " 'one': 7,\n",
       " '”': 7,\n",
       " 'pastri': 6,\n",
       " 'got': 6,\n",
       " 'cake': 6,\n",
       " '…': 6,\n",
       " 'ever': 6,\n",
       " 'class': 5,\n",
       " 'friend': 5,\n",
       " 'get': 5,\n",
       " 'well': 5,\n",
       " 'breakfast': 5,\n",
       " 'go': 5,\n",
       " 'scone': 5,\n",
       " 'realli': 5,\n",
       " 'think': 5,\n",
       " 'flaki': 5,\n",
       " 'tast': 5,\n",
       " 'bread': 5,\n",
       " 'recommend': 5,\n",
       " 'even': 4,\n",
       " '<': 4,\n",
       " 'cinnamon': 4,\n",
       " 'tri': 4,\n",
       " 'seat': 4,\n",
       " 'awesom': 4,\n",
       " 'day': 4,\n",
       " 'amaz': 4,\n",
       " 'fresh': 4,\n",
       " 'blueberri': 4,\n",
       " '>': 4,\n",
       " 'outsid': 4,\n",
       " 'css': 4,\n",
       " 'world': 4,\n",
       " 'bold': 4,\n",
       " 'everyth': 4,\n",
       " 'span': 4,\n",
       " \"''\": 4,\n",
       " 'muffin': 4,\n",
       " 'data': 4,\n",
       " 'donut': 4,\n",
       " '/': 4,\n",
       " 'enjoy': 4,\n",
       " 'staff': 4,\n",
       " '1egxyvc': 4,\n",
       " '=': 4,\n",
       " 'font': 4,\n",
       " 'weight': 4,\n",
       " '$': 4,\n",
       " 'tea': 4,\n",
       " 'place': 4,\n",
       " 'order': 4,\n",
       " 'servic': 3,\n",
       " 'alway': 3,\n",
       " 'back': 3,\n",
       " ';': 3,\n",
       " 'favorit': 3,\n",
       " 'need': 3,\n",
       " 'select': 3,\n",
       " 'local': 3,\n",
       " 'danish': 3,\n",
       " 'super': 3,\n",
       " 'cooki': 3,\n",
       " 'return': 3,\n",
       " 'amp': 3,\n",
       " 'butteri': 3,\n",
       " 'flavor': 3,\n",
       " 'yummi': 3,\n",
       " 'top': 3,\n",
       " 'bean': 3,\n",
       " 'ice': 3,\n",
       " 'first': 3,\n",
       " 'sweet': 3,\n",
       " 'nice': 3,\n",
       " 'milk': 3,\n",
       " 'say': 3,\n",
       " 'area': 3,\n",
       " 'often': 2,\n",
       " 'take': 2,\n",
       " 'water': 2,\n",
       " 'around': 2,\n",
       " 'fill': 2,\n",
       " 'time': 2,\n",
       " 'hazelnut': 2,\n",
       " 'turkey': 2,\n",
       " 'tart': 2,\n",
       " 'sit': 2,\n",
       " 'countri': 2,\n",
       " 'includ': 2,\n",
       " 'love': 2,\n",
       " 'life': 2,\n",
       " 'busi': 2,\n",
       " 'almost': 2,\n",
       " 'soft': 2,\n",
       " 'highlight': 2,\n",
       " 'au': 2,\n",
       " 'chai': 2,\n",
       " 'experi': 2,\n",
       " 'cafe': 2,\n",
       " 'energi': 2,\n",
       " 'bring': 2,\n",
       " 'bake': 2,\n",
       " 'could': 2,\n",
       " 'work': 2,\n",
       " 'dri': 2,\n",
       " 'high': 2,\n",
       " 'shop': 2,\n",
       " 'disappoint': 2,\n",
       " 'slice': 2,\n",
       " 'eat': 2,\n",
       " 'probabl': 2,\n",
       " 'uniqu': 2,\n",
       " 'quit': 2,\n",
       " 'small': 2,\n",
       " 'quich': 2,\n",
       " 'sinc': 2,\n",
       " 'treat': 2,\n",
       " 'kind': 2,\n",
       " 'fruit': 2,\n",
       " '4': 2,\n",
       " 'definit': 2,\n",
       " '5': 2,\n",
       " 'hint': 2,\n",
       " 'scratch': 2,\n",
       " 'hour': 2,\n",
       " 'hot': 2,\n",
       " 'excel': 2,\n",
       " 'fritter': 2,\n",
       " 'roll': 2,\n",
       " 'music': 2,\n",
       " 'bakeri': 2,\n",
       " 'fun': 2,\n",
       " 'appl': 2,\n",
       " 'huge': 2,\n",
       " 'various': 2,\n",
       " 'enough': 2,\n",
       " 'name': 2,\n",
       " '50': 2,\n",
       " 'would': 2,\n",
       " 'thing': 2,\n",
       " 'bit': 2,\n",
       " 'way': 2,\n",
       " 'bagel': 2,\n",
       " 'oat': 2,\n",
       " 'lavend': 2,\n",
       " 'tasti': 1,\n",
       " 'brioch': 1,\n",
       " 'cold': 1,\n",
       " 'ad': 1,\n",
       " 'actual': 1,\n",
       " 'size': 1,\n",
       " 'lemon': 1,\n",
       " 'surpris': 1,\n",
       " 'ran': 1,\n",
       " 'nut': 1,\n",
       " 'cupcak': 1,\n",
       " 'sheep': 1,\n",
       " 'worth': 1,\n",
       " 'meringu': 1,\n",
       " 'europ': 1,\n",
       " 'nicest': 1,\n",
       " ':': 1,\n",
       " 'crisp': 1,\n",
       " 'check': 1,\n",
       " 'sticki': 1,\n",
       " 'flaw': 1,\n",
       " 'without': 1,\n",
       " 'sometim': 1,\n",
       " 'castella': 1,\n",
       " 'remain': 1,\n",
       " 'coupl': 1,\n",
       " 'away': 1,\n",
       " 'cortado': 1,\n",
       " 'knock': 1,\n",
       " 'cheesi': 1,\n",
       " 'spread': 1,\n",
       " 'far': 1,\n",
       " 'warm': 1,\n",
       " 'oatmeal': 1,\n",
       " 'aw': 1,\n",
       " 'told': 1,\n",
       " 'worst': 1,\n",
       " 'general': 1,\n",
       " 'held': 1,\n",
       " 'nosh': 1,\n",
       " '18': 1,\n",
       " 'strawberri': 1,\n",
       " 'street': 1,\n",
       " 'window': 1,\n",
       " 'still': 1,\n",
       " 'reason': 1,\n",
       " 'excit': 1,\n",
       " 'powder': 1,\n",
       " 'gem': 1,\n",
       " 'admixtur': 1,\n",
       " 'light': 1,\n",
       " 'three': 1,\n",
       " 'bench': 1,\n",
       " 'decid': 1,\n",
       " 'strong': 1,\n",
       " 'over': 1,\n",
       " 'macaroon': 1,\n",
       " 'mug': 1,\n",
       " 'whole': 1,\n",
       " 'mini': 1,\n",
       " 'wonder': 1,\n",
       " 'pumpkin': 1,\n",
       " 'potato': 1,\n",
       " 'touch': 1,\n",
       " 'stale': 1,\n",
       " 'w': 1,\n",
       " 'vegan': 1,\n",
       " 'horchata': 1,\n",
       " 'higher': 1,\n",
       " 'pour': 1,\n",
       " 'north': 1,\n",
       " 'lakeview': 1,\n",
       " 'rich': 1,\n",
       " 'owner': 1,\n",
       " 'remind': 1,\n",
       " 'oven': 1,\n",
       " 'veggi': 1,\n",
       " 'cute': 1,\n",
       " 'daughter': 1,\n",
       " 'fireplac': 1,\n",
       " 'buck': 1,\n",
       " 'bun': 1,\n",
       " 'cooler': 1,\n",
       " 'averag': 1,\n",
       " 'goldi': 1,\n",
       " 'chang': 1,\n",
       " 'ok': 1,\n",
       " 'citi': 1,\n",
       " 'right': 1,\n",
       " 'perhap': 1,\n",
       " 'third': 1,\n",
       " 'add': 1,\n",
       " 'mention': 1,\n",
       " 'doughnut': 1,\n",
       " 'search': 1,\n",
       " 'eqq': 1,\n",
       " 'bravo': 1,\n",
       " 'browni': 1,\n",
       " 'chose': 1,\n",
       " 'girl': 1,\n",
       " '12': 1,\n",
       " 'pie': 1,\n",
       " 'bacon': 1,\n",
       " 'refri': 1,\n",
       " 'absolut': 1,\n",
       " 'pair': 1,\n",
       " 'die': 1,\n",
       " 'addit': 1,\n",
       " 'cup': 1,\n",
       " 'effici': 1,\n",
       " 'equal': 1,\n",
       " 'middl': 1,\n",
       " '16oz': 1,\n",
       " 'sure': 1,\n",
       " 'make': 1,\n",
       " 'usual': 1,\n",
       " 'crust': 1,\n",
       " 'spinach': 1,\n",
       " 'hostess': 1,\n",
       " 'showcas': 1,\n",
       " 'chef': 1,\n",
       " 'cheap': 1,\n",
       " 'price': 1,\n",
       " 'weak': 1,\n",
       " 'sugari': 1,\n",
       " 'larg': 1,\n",
       " 'felt': 1,\n",
       " 'french': 1,\n",
       " 'stuff': 1,\n",
       " 'winter': 1,\n",
       " 'expert': 1,\n",
       " 'bronzevill': 1,\n",
       " 'assort': 1,\n",
       " 'park': 1,\n",
       " 'crumbl': 1,\n",
       " 'wait': 1,\n",
       " 'meg': 1,\n",
       " 'blackberri': 1,\n",
       " 'may': 1,\n",
       " 'pita': 1,\n",
       " 'qualiti': 1,\n",
       " 'savori': 1,\n",
       " 'thin': 1,\n",
       " 'arriv': 1,\n",
       " 'somehow': 1,\n",
       " 'sugar': 1,\n",
       " 'everi': 1,\n",
       " 'opinion': 1,\n",
       " 'howev': 1,\n",
       " 'schaumburg': 1,\n",
       " 'regular': 1,\n",
       " 'cocktail': 1,\n",
       " 'interior': 1,\n",
       " 'orang': 1,\n",
       " 'mac': 1,\n",
       " 'truffl': 1,\n",
       " '?': 1,\n",
       " 'rustic': 1,\n",
       " 'sesam': 1,\n",
       " 'key': 1,\n",
       " 'beauti': 1,\n",
       " 'waffl': 1,\n",
       " 'raisin': 1,\n",
       " 'anywher': 1,\n",
       " '63rd': 1,\n",
       " 'minor': 1,\n",
       " 'recip': 1,\n",
       " 'welcom': 1,\n",
       " 'surgeri': 1,\n",
       " 'red': 1,\n",
       " 'ask': 1,\n",
       " 'damn': 1,\n",
       " 'limit': 1,\n",
       " 'els': 1,\n",
       " 'inventori': 1,\n",
       " 'took': 1,\n",
       " 'walk': 1,\n",
       " 'along': 1,\n",
       " 'serv': 1,\n",
       " 'bloat': 1,\n",
       " 'pictur': 1,\n",
       " 'today': 1,\n",
       " 'nutella': 1,\n",
       " 'notch': 1,\n",
       " 'jam': 1,\n",
       " 'cream': 1,\n",
       " 'pain': 1,\n",
       " 'morn': 1,\n",
       " 'someth': 1,\n",
       " 'reliv': 1,\n",
       " 'record': 1,\n",
       " 'visit': 1,\n",
       " '2': 1,\n",
       " 'onion': 1,\n",
       " 'sell': 1,\n",
       " 'glutton': 1,\n",
       " 'show': 1,\n",
       " 'groceri': 1,\n",
       " 'fanci': 1,\n",
       " 'authent': 1,\n",
       " 'blew': 1,\n",
       " 'gift': 1,\n",
       " 'part': 1,\n",
       " 'cardamom': 1,\n",
       " 'fluffi': 1,\n",
       " 'find': 1,\n",
       " 'feel': 1,\n",
       " 'never': 1,\n",
       " 'academi': 1,\n",
       " 'talerico': 1,\n",
       " 'pretti': 1,\n",
       " 'oz': 1,\n",
       " 'west': 1,\n",
       " 'cider': 1,\n",
       " 'eight': 1,\n",
       " 'thank': 1,\n",
       " 'dream': 1,\n",
       " 'sip': 1,\n",
       " 'pecan': 1,\n",
       " 'dark': 1,\n",
       " 'lover': 1,\n",
       " 'lot': 1,\n",
       " 'among': 1,\n",
       " 'desert': 1,\n",
       " 'quiet': 1,\n",
       " 'dip': 1,\n",
       " 'secret': 1,\n",
       " 'eaten': 1,\n",
       " 'two': 1,\n",
       " 'center': 1,\n",
       " ',': 1,\n",
       " 'unusu': 1,\n",
       " 'perfect': 1,\n",
       " 'teach': 1,\n",
       " 'parisian': 1,\n",
       " 'cbd': 1,\n",
       " 'incred': 1,\n",
       " 'sausag': 1,\n",
       " 'lunch': 1,\n",
       " 'start': 1,\n",
       " 'bae': 1,\n",
       " 'pistachio': 1,\n",
       " 'side': 1,\n",
       " 'popov': 1,\n",
       " 'decent': 1,\n",
       " 'wish': 1,\n",
       " 'delect': 1,\n",
       " 'tamal': 1,\n",
       " 'yes': 1,\n",
       " 'second': 1,\n",
       " 'abl': 1,\n",
       " 'rank': 1,\n",
       " 'drove': 1,\n",
       " 'extens': 1,\n",
       " 'macaron': 1,\n",
       " 'petal': 1,\n",
       " 'mind': 1,\n",
       " 'though': 1,\n",
       " 'kolach': 1,\n",
       " 'voss': 1,\n",
       " 'crawffl': 1,\n",
       " 'recent': 1,\n",
       " 'sale': 1,\n",
       " '3': 1,\n",
       " 'menu': 1,\n",
       " 'mocha': 1,\n",
       " 'minut': 1,\n",
       " 'lest': 1,\n",
       " 'twice': 1,\n",
       " 'kick': 1,\n",
       " 'togeth': 1,\n",
       " 'cool': 1,\n",
       " 'rememb': 1,\n",
       " 'watch': 1,\n",
       " 'caffein': 1,\n",
       " 'post': 1,\n",
       " 'wall': 1,\n",
       " 'loud': 1,\n",
       " 'rose': 1,\n",
       " 'egg': 1,\n",
       " 'extrem': 1,\n",
       " 'form': 1,\n",
       " 'drive': 1,\n",
       " 'glori': 1,\n",
       " 'adult': 1,\n",
       " 'ador': 1,\n",
       " 'use': 1,\n",
       " 'section': 1,\n",
       " 'seed': 1,\n",
       " 'crunchi': 1,\n",
       " 'neighborhood': 1,\n",
       " 'truli': 1,\n",
       " 'baguett': 1,\n",
       " 'martin': 1,\n",
       " 'young': 1,\n",
       " 'chocolat': 1,\n",
       " 'hook': 1,\n",
       " 'lack': 1,\n",
       " 'transit': 1,\n",
       " 'art': 1,\n",
       " 'soup': 1,\n",
       " '14': 1,\n",
       " 'look': 1,\n",
       " 'st': 1,\n",
       " 'bechemel': 1,\n",
       " 'panini': 1,\n",
       " 'croqu': 1,\n",
       " 'kid': 1,\n",
       " 'lock': 1,\n",
       " 'raw': 1,\n",
       " 'design': 1,\n",
       " 'despit': 1,\n",
       " 'fine': 1,\n",
       " 'butter': 1,\n",
       " 'charm': 1,\n",
       " 'risk': 1,\n",
       " 'dessert': 1,\n",
       " 'stop': 1,\n",
       " 'fantast': 1,\n",
       " 'babi': 1,\n",
       " 'def': 1,\n",
       " 'syrup': 1,\n",
       " 'choic': 1,\n",
       " 'strangest': 1,\n",
       " 'drink': 1,\n",
       " 'worker': 1,\n",
       " 'came': 1,\n",
       " 'seduct': 1,\n",
       " 'program': 1,\n",
       " 'certain': 1,\n",
       " 'feta': 1,\n",
       " 'fan': 1,\n",
       " 'indecis': 1,\n",
       " 'crumb': 1,\n",
       " 'moist': 1,\n",
       " 'chicago': 1,\n",
       " 'luck': 1,\n",
       " 'clear': 1,\n",
       " 'woman': 1,\n",
       " 'lime': 1,\n",
       " 'instructor': 1,\n",
       " 'mousier': 1,\n",
       " 'vinyl': 1,\n",
       " 'hearti': 1,\n",
       " 'dog': 1,\n",
       " 'member': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(map(pd.Series, df['word_count'])).index.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N E ways\n",
    "\n",
    "df['label'] = \"\"\n",
    "df.to_csv(\"unlabeled_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16oz</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   $  12  14  16oz  18\n",
       "0  0   0   0     0   0\n",
       "1  0   0   0     0   0\n",
       "2  0   0   0     0   0\n",
       "3  0   0   0     0   0\n",
       "4  0   0   0     0   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer=lambda abc: abc)\n",
    "counted_values = cv.fit_transform(df['Review_Prepped']).toarray() #previously ReviewPrepped\n",
    "cv_df = pd.DataFrame(counted_values, columns=cv.get_feature_names())\n",
    "cv_df.iloc[0:5, 0:5]\n",
    "\n",
    "#https://towardsdatascience.com/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
