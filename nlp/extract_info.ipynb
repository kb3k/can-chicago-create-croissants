{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-77ed66c9e225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m \u001b[0;31m# texthero, spacy, and nltk do not seem to align; pick 1-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import spacy # texthero, spacy, and nltk do not seem to align; pick 1-2\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_str1 = '<span class=\"css-1egxyvc\" data-font-weight=\"bold\">croissant</span>'\n",
    "replace_str2 = '<span class=\"css-1egxyvc\" data-font-weight=\"bold\">croissants</span>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "\n",
    "with open(\"../archive/reviews.txt\", \"r\") as the_file:\n",
    "    while True:\n",
    "        line = the_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        elif len(line) > 3: # \\n\n",
    "            line = line.replace(replace_str1, \"croissant\")\n",
    "            line = line.replace(replace_str2, \"croissant\")\n",
    "            reviews.append(line)\n",
    "\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lost larson bakery : These are the best cinnamon rolls ever. The croissant are also delicious and the service is very efficient”\\n', 'bang bang pie and biscuits : reminded me of a croissant) and light. The actual filling was very good and you can clearly taste”\\n', 'good ambler : minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n']\n"
     ]
    }
   ],
   "source": [
    "print(reviews[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idx0</th>\n",
       "      <td>hendrickx belgian bread crafter</td>\n",
       "      <td>The almond chocolate croissant and french coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx1</th>\n",
       "      <td>lost larson bakery</td>\n",
       "      <td>These are the best cinnamon rolls ever. The cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx2</th>\n",
       "      <td>bang bang pie and biscuits</td>\n",
       "      <td>reminded me of a croissant) and light. The act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx3</th>\n",
       "      <td>good ambler</td>\n",
       "      <td>minutes. - Ham and cheese croissant: croissant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx4</th>\n",
       "      <td>p%C3%A2tisserie coralie</td>\n",
       "      <td>is a croissant desert. Search no more. Very fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            BakeryName  \\\n",
       "index                                    \n",
       "idx0   hendrickx belgian bread crafter   \n",
       "idx1                lost larson bakery   \n",
       "idx2        bang bang pie and biscuits   \n",
       "idx3                       good ambler   \n",
       "idx4           p%C3%A2tisserie coralie   \n",
       "\n",
       "                                                  Review  \n",
       "index                                                     \n",
       "idx0   The almond chocolate croissant and french coun...  \n",
       "idx1   These are the best cinnamon rolls ever. The cr...  \n",
       "idx2   reminded me of a croissant) and light. The act...  \n",
       "idx3   minutes. - Ham and cheese croissant: croissant...  \n",
       "idx4   is a croissant desert. Search no more. Very fr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I like this version better but pandas words differently, so later we conform\n",
    "dict_reviews = {review.split(' : ')[0]: review.split(' : ')[1] for review in reviews}\n",
    "\n",
    "names = list(dict_reviews.keys())\n",
    "words = list(dict_reviews.values())\n",
    "index = ['idx'+str(idx) for idx in range(0, len(names))]\n",
    "dict_for_pd = {'index': index, 'BakeryName': names, 'Review': words}\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_for_pd)\n",
    "df.set_index(\"index\", inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idx3</th>\n",
       "      <td>good ambler</td>\n",
       "      <td>minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx16</th>\n",
       "      <td>hoosier mama pie company</td>\n",
       "      <td>and cream admixture and a flaky buttery crust almost like that of a croissant. Indecisive and gluttonous as”\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx33</th>\n",
       "      <td>caffe umbria</td>\n",
       "      <td>are the highlight of the show, you absolutely have to get a croissant - it was so flaky and buttery and the muffin was also moist and had a hint of cinnamon!!!”\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx39</th>\n",
       "      <td>abc bakery and deli norridge?hrid=SDxAypM6HgjzV47KHlp0TQ&amp;amp;osq=croissant\"&gt;more&lt;/a&gt;&lt;/span&gt;&lt;/p</td>\n",
       "      <td>of the seductive sweets. I chose a nutella croissant! Fluffy, flaky, sticky hazelnut spread glory. Yes”\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           BakeryName  \\\n",
       "index                                                                                                   \n",
       "idx3                                                                                      good ambler   \n",
       "idx16                                                                        hoosier mama pie company   \n",
       "idx33                                                                                    caffe umbria   \n",
       "idx39  abc bakery and deli norridge?hrid=SDxAypM6HgjzV47KHlp0TQ&amp;osq=croissant\">more</a></span></p   \n",
       "\n",
       "                                                                                                                                                                   Review  \n",
       "index                                                                                                                                                                      \n",
       "idx3                                                             minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n  \n",
       "idx16                                                      and cream admixture and a flaky buttery crust almost like that of a croissant. Indecisive and gluttonous as”\\n  \n",
       "idx33  are the highlight of the show, you absolutely have to get a croissant - it was so flaky and buttery and the muffin was also moist and had a hint of cinnamon!!!”\\n  \n",
       "idx39                                                           of the seductive sweets. I chose a nutella croissant! Fluffy, flaky, sticky hazelnut spread glory. Yes”\\n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some peering\n",
    "pd.options.display.max_colwidth = None\n",
    "df[df['Review'].str.contains(\"flak\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoosier mama is not a review on a croissant\n",
    "# not a huge nutella fan, it's just sugar. too easy\n",
    "# caffe umbria and good ambler are the winners based on this.\n",
    "# but let's do more with these reviews\n",
    "# while we r here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BakeryName, Review]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Review'].str.contains(\"artisan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing, filtering stop words, stemming, and lower casing\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words = stop_words.union({'!', '!!!', '!!!”', '!)', '!),', '!?', '!”', '\"', '\">', '.', \"'\", '\\n'\\\n",
    "                               '&', '(', ')', '),', ').', '+', ',', '-', '--', '&', '...', '.”', '/'})\n",
    "\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_Prepped'] = df.Review.apply(lambda xyz: \n",
    "                                       [stemmer.stem(word.lower()) \n",
    "                                        for word in wordpunct_tokenize(xyz) \n",
    "                                        if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BakeryName</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Prepped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>idx0</th>\n",
       "      <td>hendrickx belgian bread crafter</td>\n",
       "      <td>The almond chocolate croissant and french country bread were quite authentic and wonderfully rustic.”\\n</td>\n",
       "      <td>[almond, chocol, croissant, french, countri, bread, quit, authent, wonder, rustic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx1</th>\n",
       "      <td>lost larson bakery</td>\n",
       "      <td>These are the best cinnamon rolls ever. The croissant are also delicious and the service is very efficient”\\n</td>\n",
       "      <td>[best, cinnamon, roll, ever, croissant, also, delici, servic, effici, ”]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx2</th>\n",
       "      <td>bang bang pie and biscuits</td>\n",
       "      <td>reminded me of a croissant) and light. The actual filling was very good and you can clearly taste”\\n</td>\n",
       "      <td>[remind, croissant, light, actual, fill, good, clear, tast, ”]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx3</th>\n",
       "      <td>good ambler</td>\n",
       "      <td>minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n</td>\n",
       "      <td>[minut, ham, chees, croissant, :, croissant, super, flaki, sesam, seed, nice, touch, ”]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx4</th>\n",
       "      <td>p%C3%A2tisserie coralie</td>\n",
       "      <td>is a croissant desert. Search no more. Very friendly staff, great tea and coffee. A truly welcome addition to the neighborhood. Best of luck.”\\n</td>\n",
       "      <td>[croissant, desert, search, friend, staff, great, tea, coffe, truli, welcom, addit, neighborhood, best, luck]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            BakeryName  \\\n",
       "index                                    \n",
       "idx0   hendrickx belgian bread crafter   \n",
       "idx1                lost larson bakery   \n",
       "idx2        bang bang pie and biscuits   \n",
       "idx3                       good ambler   \n",
       "idx4           p%C3%A2tisserie coralie   \n",
       "\n",
       "                                                                                                                                                 Review  \\\n",
       "index                                                                                                                                                     \n",
       "idx0                                            The almond chocolate croissant and french country bread were quite authentic and wonderfully rustic.”\\n   \n",
       "idx1                                      These are the best cinnamon rolls ever. The croissant are also delicious and the service is very efficient”\\n   \n",
       "idx2                                               reminded me of a croissant) and light. The actual filling was very good and you can clearly taste”\\n   \n",
       "idx3                                           minutes. - Ham and cheese croissant: croissant was super flaky and the sesame seeds were a nice touch”\\n   \n",
       "idx4   is a croissant desert. Search no more. Very friendly staff, great tea and coffee. A truly welcome addition to the neighborhood. Best of luck.”\\n   \n",
       "\n",
       "                                                                                                      Review_Prepped  \n",
       "index                                                                                                                 \n",
       "idx0                              [almond, chocol, croissant, french, countri, bread, quit, authent, wonder, rustic]  \n",
       "idx1                                        [best, cinnamon, roll, ever, croissant, also, delici, servic, effici, ”]  \n",
       "idx2                                                  [remind, croissant, light, actual, fill, good, clear, tast, ”]  \n",
       "idx3                         [minut, ham, chees, croissant, :, croissant, super, flaki, sesam, seed, nice, touch, ”]  \n",
       "idx4   [croissant, desert, search, friend, staff, great, tea, coffe, truli, welcom, addit, neighborhood, best, luck]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "semantic analysis ?\n",
    "\n",
    "if someone writes a review on a croissant in chicago, \n",
    "what are they likely to say about it. .. https://www.nltk.org/howto/classify.html\n",
    "or https://www.nltk.org/howto/probability.html\n",
    "\n",
    ">>> from nltk.classify import SklearnClassifier\n",
    ">>> from sklearn.naive_bayes import BernoulliNB\n",
    ">>> from sklearn.svm import SVC\n",
    ">>> train_data = [({\"a\": 4, \"b\": 1, \"c\": 0}, \"ham\"),\n",
    "...               ({\"a\": 5, \"b\": 2, \"c\": 1}, \"ham\"),\n",
    "...               ({\"a\": 0, \"b\": 3, \"c\": 4}, \"spam\"),\n",
    "...               ({\"a\": 5, \"b\": 1, \"c\": 1}, \"ham\"),\n",
    "...               ({\"a\": 1, \"b\": 4, \"c\": 3}, \"spam\")]\n",
    ">>> classif = SklearnClassifier(BernoulliNB()).train(train_data)\n",
    ">>> test_data = [{\"a\": 3, \"b\": 2, \"c\": 1},\n",
    "...              {\"a\": 0, \"b\": 3, \"c\": 7}]\n",
    ">>> classif.classify_many(test_data)\n",
    "['ham', 'spam']\n",
    ">>> classif = SklearnClassifier(SVC(), sparse=False).train(train_data)\n",
    ">>> classif.classify_many(test_data)\n",
    "['ham', 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RegistryError",
     "evalue": "[E893] Could not find function 'spacy.MultiHashEmbed.v2' in function registry 'architectures'. If you're using a custom function, make sure the code is available. If the function is provided by a third-party package, e.g. spacy-transformers, make sure the package is installed in your environment.\n\nAvailable names: spacy-legacy.CharacterEmbed.v1, spacy-legacy.EntityLinker.v1, spacy-legacy.HashEmbedCNN.v1, spacy-legacy.MaxoutWindowEncoder.v1, spacy-legacy.MishWindowEncoder.v1, spacy-legacy.MultiHashEmbed.v1, spacy-legacy.Tagger.v1, spacy-legacy.TextCatBOW.v1, spacy-legacy.TextCatCNN.v1, spacy-legacy.TextCatEnsemble.v1, spacy-legacy.Tok2Vec.v1, spacy-legacy.TransitionBasedParser.v1, spacy.CharacterEmbed.v1, spacy.EntityLinker.v1, spacy.HashEmbedCNN.v1, spacy.MaxoutWindowEncoder.v2, spacy.MishWindowEncoder.v2, spacy.MultiHashEmbed.v1, spacy.PretrainCharacters.v1, spacy.PretrainVectors.v1, spacy.Tagger.v1, spacy.TextCatBOW.v1, spacy.TextCatCNN.v1, spacy.TextCatEnsemble.v2, spacy.TextCatLowData.v1, spacy.Tok2Vec.v2, spacy.Tok2VecListener.v1, spacy.TorchBiLSTMEncoder.v1, spacy.TransitionBasedParser.v1, spacy.TransitionBasedParser.v2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRegistryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8d092272a28e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, disable, exclude, config)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/en_core_web_sm/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_config\u001b[0;34m(config, vocab, disable, exclude, auto_fill, validate)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, vocab, disable, exclude, meta, auto_fill, validate)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[1;32m    745\u001b[0m     ) -> Dict[str, Any]:\n\u001b[1;32m    746\u001b[0m         resolved, _ = cls._make(\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         )\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresolved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_make\u001b[0;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         filled, _, resolved = cls._fill(\n\u001b[0;32m--> 796\u001b[0;31m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    798\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msection_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_parent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                     \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m                 )\n\u001b[1;32m    858\u001b[0m                 \u001b[0mreg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_parent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                     \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m                 )\n\u001b[1;32m    858\u001b[0m                 \u001b[0mreg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m_fill\u001b[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[1;32m    847\u001b[0m                     \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m                     \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fields__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_model_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m                 \u001b[0mpromise_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_promise_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m                 filled[key], validation[v_key], final[key] = cls._fill(\n\u001b[1;32m    851\u001b[0m                     \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36mmake_promise_schema\u001b[0;34m(cls, obj, resolve)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresolve\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mEmptySchema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;31m# Read the argument annotations and defaults from the function signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0mid_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(cls, registry_name, func_name)\u001b[0m\n",
      "\u001b[0;31mRegistryError\u001b[0m: [E893] Could not find function 'spacy.MultiHashEmbed.v2' in function registry 'architectures'. If you're using a custom function, make sure the code is available. If the function is provided by a third-party package, e.g. spacy-transformers, make sure the package is installed in your environment.\n\nAvailable names: spacy-legacy.CharacterEmbed.v1, spacy-legacy.EntityLinker.v1, spacy-legacy.HashEmbedCNN.v1, spacy-legacy.MaxoutWindowEncoder.v1, spacy-legacy.MishWindowEncoder.v1, spacy-legacy.MultiHashEmbed.v1, spacy-legacy.Tagger.v1, spacy-legacy.TextCatBOW.v1, spacy-legacy.TextCatCNN.v1, spacy-legacy.TextCatEnsemble.v1, spacy-legacy.Tok2Vec.v1, spacy-legacy.TransitionBasedParser.v1, spacy.CharacterEmbed.v1, spacy.EntityLinker.v1, spacy.HashEmbedCNN.v1, spacy.MaxoutWindowEncoder.v2, spacy.MishWindowEncoder.v2, spacy.MultiHashEmbed.v1, spacy.PretrainCharacters.v1, spacy.PretrainVectors.v1, spacy.Tagger.v1, spacy.TextCatBOW.v1, spacy.TextCatCNN.v1, spacy.TextCatEnsemble.v2, spacy.TextCatLowData.v1, spacy.Tok2Vec.v2, spacy.Tok2VecListener.v1, spacy.TorchBiLSTMEncoder.v1, spacy.TransitionBasedParser.v1, spacy.TransitionBasedParser.v2"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_return = []\n",
    "\n",
    "def many_things(string_of_text):\n",
    "    \"\"\"\n",
    "    uses the spacy package to \n",
    "    label words in case its important\n",
    "    to differentiate can and can in the following\n",
    "    sent. as ex. . .\n",
    "    \n",
    "    i can kick the can down the road\n",
    "    \"\"\"\n",
    "    nlp_mjx = nlp(string_of_text)\n",
    "    for ent in nlp_mjx.ents:\n",
    "        info = str(ent.text) + \" | \" + str(ent.label_)\n",
    "        items_to_return.append(info)\n",
    "    return items_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spacy_NLP_ids'] = df['Review'].apply(lambda mjx: many_things(mjx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer=lambda abc: abc)\n",
    "counted_values = cv.fit_transform(df['Review_Prepped']).toarray() #previously ReviewPrepped\n",
    "cv_df = pd.DataFrame(counted_values, columns=cv.get_feature_names())\n",
    "cv_df.iloc[0:5, 0:5]\n",
    "\n",
    "#https://towardsdatascience.com/how-to-vectorize-text-in-dataframes-for-nlp-tasks-3-simple-techniques-82925a5600db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
